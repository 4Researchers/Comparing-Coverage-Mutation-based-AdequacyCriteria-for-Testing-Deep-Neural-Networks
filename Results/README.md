## Results

In this study, we had two research question:

1- Which of the two metrics (Surprise Coverage or Label Change Rate) is more effective in detecting adversarial examples?

2- How sensitive the two metrics are with respect to changing parameters?

As figures below show, our study shows that the conclusion for RQ1 is when applying LCR and LSC, using the default or suggested parameters, on two DNN models on MNIST, Label Change Rate (LCR), which is based on model mutation, is more effective than Likelihood Surprise Coverage (LSC), which is based on neuron coverage, in detecting adversarial examples.
 

![h](/MNIST-CONV5.png)

![j](/MNIST-LENET.png)
